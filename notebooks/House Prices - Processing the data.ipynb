{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices - Processing the data\n",
    "\n",
    "Based on the work with the EDA and Feature refinement notebooks, start to create a clean dataset that can be used for training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "1         Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "2         Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "3         Lvl    AllPub    Corner  ...        0    NaN   NaN         NaN   \n",
       "4         Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0       0      2    2008        WD         Normal     208500  \n",
       "1       0      5    2007        WD         Normal     181500  \n",
       "2       0      9    2008        WD         Normal     223500  \n",
       "3       0      2    2006        WD        Abnorml     140000  \n",
       "4       0     12    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check which platform is running the notebook\n",
    "if platform.system() == 'Windows':\n",
    "    PROJECT_PATH = \"\\\\\".join(os.getcwd().split('\\\\')[:-1])\n",
    "else:\n",
    "    # Assuming a Unix based platform\n",
    "    PROJECT_PATH = \"/\".join(os.getcwd().split('/')[:-1])\n",
    "\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, 'data')\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
    "\n",
    "# Load the training dataset\n",
    "house_prices_train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "house_prices_train = house_prices_train.drop('Id', axis=1)\n",
    "house_prices_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the columns\n",
    "\n",
    "Getting the columns that were considered the best ones to use from the EDA notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    'LotFrontage',\n",
    "    'LotArea', 'YearBuilt',\n",
    "    'MasVnrArea',\n",
    "    'BsmtFinSF1',\n",
    "    'BsmtFinSF2',\n",
    "    'BsmtUnfSF',\n",
    "    'TotalBsmtSF',\n",
    "    '1stFlrSF',\n",
    "    '2ndFlrSF', \n",
    "    'GrLivArea', \n",
    "    'GarageYrBlt', \n",
    "    'GarageArea', \n",
    "    'WoodDeckSF', \n",
    "    'OpenPorchSF', \n",
    "    'EnclosedPorch', \n",
    "    'ScreenPorch', \n",
    "]\n",
    "\n",
    "ordinal_features = [\n",
    "    'GarageCond',\n",
    "    'GarageQual',\n",
    "    'FireplaceQu',\n",
    "    'KitchenQual',\n",
    "    'HeatingQC',\n",
    "    'BsmtFinType2',\n",
    "    'BsmtFinType1',\n",
    "    'BsmtExposure',\n",
    "    'BsmtCond',\n",
    "    'BsmtQual',\n",
    "    'ExterCond',\n",
    "    'ExterQual'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'MSZoning',\n",
    "    'Street',\n",
    "    'LotShape',\n",
    "    'LandContour',\n",
    "    'Utilities',\n",
    "    'LotConfig',\n",
    "    'LandSlope',\n",
    "    'Neighborhood',\n",
    "    'Condition1',\n",
    "    'Condition2',\n",
    "    'BldgType',\n",
    "    'HouseStyle', \n",
    "    'RoofStyle',\n",
    "    'RoofMatl',\n",
    "    'Exterior1st',\n",
    "    'Exterior2nd',\n",
    "    'MasVnrType',\n",
    "    'Foundation',\n",
    "    'Heating',\n",
    "    'CentralAir',\n",
    "    'Electrical',\n",
    "    'Functional',\n",
    "    'GarageType',\n",
    "    'GarageFinish',\n",
    "    'PavedDrive',\n",
    "    'SaleType',\n",
    "    'SaleCondition'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing in the processing pipeline class from the EDA notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "class FeatureExtractor(TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.cols]\n",
    "\n",
    "class HouseDataProcessor(object):\n",
    "    def __init__(self, numeric_cols, ordinal_cols, categorical_cols):\n",
    "        self.numeric_cols = numeric_cols\n",
    "        self.ordinal_cols = ordinal_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        \n",
    "        self.numeric_pipeline_v1 = Pipeline([\n",
    "            ('extractor', FeatureExtractor(self.numeric_cols)),\n",
    "            ('impute', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        self.ordinal_pipeline_v1 = Pipeline([\n",
    "            ('extractor', FeatureExtractor(self.ordinal_cols)),\n",
    "            ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ordinal', OrdinalEncoder())\n",
    "        ])\n",
    "\n",
    "        self.categorical_pipeline_v1 = Pipeline([\n",
    "            ('extractor', FeatureExtractor(self.categorical_cols)),\n",
    "            ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "            ('one_hot', OneHotEncoder())\n",
    "        ])\n",
    "\n",
    "        self.processing_pipeline_v1 = FeatureUnion([\n",
    "            ('numeric', self.numeric_pipeline_v1),\n",
    "            ('ordinal', self.ordinal_pipeline_v1),\n",
    "            ('categorical', self.categorical_pipeline_v1)\n",
    "        ])\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self.processing_pipeline_v1.fit(X)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.processing_pipeline_v1.transform(X)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        return self.processing_pipeline_v1.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outlier SalesPrice\n",
    "\n",
    "Remove the extreme values from the Sale Price so it doesn't skrew the results when making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 80)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_price_data = house_prices_train['SalePrice']\n",
    "\n",
    "q1 = sale_price_data.quantile(0.25)\n",
    "q3 = sale_price_data.quantile(0.75)\n",
    "iqr = (q3 - q1)\n",
    "\n",
    "# Extract the outliers sale price from the data\n",
    "outliers = house_prices_train[(sale_price_data < (q1 - 1.5 * iqr)) | (sale_price_data > (q3 + 1.5 * iqr))]\n",
    "outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1399, 80)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the indexes that don't appear in the outlier list\n",
    "inlier_index = ~house_prices_train.index.isin(outliers.index)\n",
    "\n",
    "# Remove the outliers from the data \n",
    "# So we are left with data that doesn't have extreme outliers\n",
    "training_data = house_prices_train[inlier_index]\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FEATURE = 'SalePrice'\n",
    "\n",
    "# Split into X and y\n",
    "X = training_data.drop(TARGET_FEATURE, axis=1)\n",
    "y = training_data[TARGET_FEATURE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a training, validation & testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size:   1007\n",
      "Val Size:     252\n",
      "Test Size:    140\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set out initial random state\n",
    "# This will be used by anything that can have its random stat defined\n",
    "RANDOM_STATE = 11\n",
    "\n",
    "# Sizes of each dataset\n",
    "train_size = 0.7\n",
    "val_size = 0.2\n",
    "test_size = 0.1\n",
    "\n",
    "# Creating Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RANDOM_STATE, test_size=test_size)\n",
    "\n",
    "# From the training set, split into trianing and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=RANDOM_STATE, test_size=val_size)\n",
    "\n",
    "print(\"Train Size: {:6}\".format(X_train.shape[0]))\n",
    "print(\"Val Size: {:7}\".format(X_val.shape[0]))\n",
    "print(\"Test Size: {:6}\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Run the data processing pipeline \n",
    "processor = HouseDataProcessor(numeric_features, ordinal_features, categorical_features)\n",
    "X_train_processed = processor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=11, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train a random forest regressor\n",
    "rand_clf_v1 = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "rand_clf_v1.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest V1 RMSE:  8610.330891854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Seeing a baseline with a basic random forest\n",
    "y_pred = rand_clf_v1.predict(X_train_processed)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print('Random Forest V1 RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For  baseline score, being around \\$8000 in terms of error isn't to bad considered we are dealing with houses that are in the hundreds of thousands. I will now try to improve this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=2)]: Done  72 out of  72 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=11,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=2,\n",
       "             param_grid=[{'criterion': ['mse', 'mae'],\n",
       "                          'n_estimators': [100, 150, 200, 250, 300, 350],\n",
       "                          'warm_start': [True, False]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [100, 150, 200, 250, 300, 350],\n",
    "        'criterion': ['mse', 'mae'],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "]\n",
    "\n",
    "rand_forest_v2 = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "grid_search_v1 = GridSearchCV(rand_forest_v2, param_grid, cv=3, n_jobs=2 , \n",
    "                              verbose=1, scoring='neg_mean_squared_error')\n",
    "grid_search_v1.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mae', 'n_estimators': 350, 'warm_start': True}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_v1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24004.819779636346"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-grid_search_v1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest V2 (Grid Search) RMSE:  8498.796786810319\n"
     ]
    }
   ],
   "source": [
    "best_estimator = grid_search_v1.best_estimator_\n",
    "\n",
    "y_pred = best_estimator.predict(X_train_processed)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print('Random Forest V2 (Grid Search) RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By performing the grid search, we have managed to reduce the error rate by around $200 dollers. However, the grid search reached the maximum parameters. I will now do a second round of training with more estimators to see if that improves things even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  18 out of  18 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=11,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=2,\n",
       "             param_grid=[{'criterion': ['mae'],\n",
       "                          'n_estimators': [350, 400, 450, 500, 550, 600],\n",
       "                          'warm_start': [True]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [350, 400, 450, 500, 550, 600],\n",
    "        'criterion': ['mae'],\n",
    "        'warm_start': [True]\n",
    "    }\n",
    "]\n",
    "\n",
    "rand_forest_v3 = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "grid_search_v2 = GridSearchCV(rand_forest_v3, param_grid, cv=3, n_jobs=2 , \n",
    "                              verbose=1, scoring='neg_mean_squared_error')\n",
    "grid_search_v2.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mae', 'n_estimators': 550, 'warm_start': True}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_v2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23971.549576257556"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-grid_search_v2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest V3 (Grid Search v2) RMSE:  8425.62355763698\n"
     ]
    }
   ],
   "source": [
    "grid_search_best_est_v2 = grid_search_v2.best_estimator_\n",
    "\n",
    "y_pred = grid_search_best_est_v2.predict(X_train_processed)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print('Random Forest V3 (Grid Search v2) RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very minor improvement for using the Random Forest model. From this, we can see that we need to apply some feature engineering to reduce the amount of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GrLivArea', 'YearBuilt', 'TotalBsmtSF', 'GarageArea', '1stFlrSF',\n",
       "       'ExterQual', 'BsmtFinSF1', 'LotArea', 'LotFrontage', 'BsmtUnfSF',\n",
       "       'GarageYrBlt', '2ndFlrSF', 'OpenPorchSF', 'MasVnrArea', 'BsmtQual',\n",
       "       'Unf', 'WoodDeckSF', 'KitchenQual', 'BsmtFinType1', 'Crawfor',\n",
       "       'BsmtExposure', 'HeatingQC', 'EnclosedPorch', 'BsmtFinSF2',\n",
       "       'ScreenPorch', 'RL', 'ExterCond', 'FireplaceQu', 'Fin', '1Fam',\n",
       "       'Attchd', 'RFn', 'Inside', 'Detchd', 'N', 'IR1', 'Reg', 'BsmtCond',\n",
       "       'Abnorml', 'Gable', 'Typ', 'Normal', 'Y', 'Corner', 'BsmtFinType2',\n",
       "       'Hip', 'CollgCr', 'BrkFace', 'CBlock', 'Edwards', 'Norm', 'RM',\n",
       "       'Stone', 'CulDSac', 'VinylSd', 'NAmes', 'VinylSd', 'Lvl', 'PConc',\n",
       "       'BrkFace', 'Wd Sdng', 'NWAmes', 'Family', 'MetalSd', 'None',\n",
       "       'NridgHt', 'Wd Sdng', 'HdBoard', 'MetalSd', '1.5Fin', 'SLvl',\n",
       "       '1Story', 'FR2', 'WD', 'Plywood', 'Plywood', 'Y', 'HdBoard',\n",
       "       'Sawyer', 'Duplex', '2Story', 'ClearCr', 'Gtl', 'Mitchel', 'Mod',\n",
       "       'Bnk', 'SBrkr', 'OldTown', 'GarageQual', 'Somerst', 'CemntBd',\n",
       "       'Mod', 'BrkSide', 'N', 'CmentBd', 'BrkTil', 'Flat', 'Timber',\n",
       "       'GarageCond', 'BuiltIn'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the most important features from the best model\n",
    "feature_importance = grid_search_best_est_v2.feature_importances_\n",
    "\n",
    "# Extract the all the one-hot categorical features\n",
    "categorical_labels = np.concatenate(processor.categorical_pipeline_v1['one_hot'].categories_)\n",
    "\n",
    "# Combine to a single array of labels\n",
    "all_labels = np.concatenate([numeric_features, ordinal_features, categorical_labels])\n",
    "\n",
    "sorted_features_index = feature_importance.argsort()[::-1]\n",
    "top_100_features_index = sorted_features_index[0:100]\n",
    "\n",
    "# See the top 100 features\n",
    "all_labels[top_100_features_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1007, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce the training dataset to only have the top 100 features\n",
    "X_train_top_100_processed = X_train_processed.toarray()[:, top_100_features_index]\n",
    "X_train_top_100_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=11, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_v4 = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "rand_forest_v4.fit(X_train_top_100_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest V4 (Top 100 features) RMSE:  8573.330968836264\n"
     ]
    }
   ],
   "source": [
    "y_pred = rand_forest_v4.predict(X_train_top_100_processed)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print('Random Forest V4 (Top 100 features) RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From reducing it to the top 100 features from the Random Forest regressor, there has been a slight improvement from the original base model. I will now train it with the best from the last round grid search (v2), to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=550, n_jobs=None, oob_score=False,\n",
       "                      random_state=11, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params = grid_search_v2.best_params_\n",
    "rand_forest_v5 = RandomForestRegressor(random_state=RANDOM_STATE, **params)\n",
    "rand_forest_v5.fit(X_train_top_100_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse_score(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest V5 (Top 100 features Best Params) RMSE:  8367.874600055844\n"
     ]
    }
   ],
   "source": [
    "rmse = get_rmse_score(rand_forest_v5, X_train_top_100_processed, y_train)\n",
    "print('Random Forest V5 (Top 100 features Best Params) RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the original baseline model that had the same params, this model is again slightly better since it has less dimensions to work with. Originally the score was 8425.62. So a slight improvement. I will now try reducing even more features to see how that affects the error score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GrLivArea', 'YearBuilt', 'TotalBsmtSF', 'GarageArea', '1stFlrSF',\n",
       "       'ExterQual', 'LotArea', 'BsmtFinSF1', 'LotFrontage', 'BsmtUnfSF',\n",
       "       'GarageYrBlt', '2ndFlrSF', 'OpenPorchSF', 'MasVnrArea', 'BsmtQual',\n",
       "       'WoodDeckSF', 'Unf', 'KitchenQual', 'BsmtFinType1', 'Crawfor',\n",
       "       'BsmtExposure', 'HeatingQC', 'EnclosedPorch', 'ScreenPorch', 'RL',\n",
       "       'ExterCond', 'BsmtFinSF2', 'FireplaceQu', 'Fin', '1Fam', 'Attchd',\n",
       "       'RFn', 'N', 'Typ', 'Normal', 'Abnorml', 'BsmtCond', 'Reg',\n",
       "       'Detchd', 'Inside', 'IR1', 'Hip', 'BsmtFinType2', 'Gable', 'Norm',\n",
       "       'Y', 'Corner', 'Edwards', 'CollgCr', 'BrkFace'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = rand_forest_v5.feature_importances_\n",
    "sorted_features_index = feature_importance.argsort()[::-1]\n",
    "top_50_features = sorted_features_index[0:50]\n",
    "\n",
    "# View the new top 50 features\n",
    "all_labels[top_100_features_index][top_50_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top 50\n",
    "X_train_top_50_processed = X_train_top_100_processed[:, top_50_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=550, n_jobs=None, oob_score=False,\n",
       "                      random_state=11, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rand_forest_v6 = RandomForestRegressor(random_state=RANDOM_STATE, **params)\n",
    "rand_forest_v6.fit(X_train_top_50_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest V6 (Top 50 features Best Params) RMSE:  8384.057470490958\n"
     ]
    }
   ],
   "source": [
    "rmse = get_rmse_score(rand_forest_v6, X_train_top_50_processed, y_train)\n",
    "print('Random Forest V6 (Top 50 features Best Params) RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the leaderboards from the Kaggle comptition, the Root Mean squared logarithmic error is the lost function that is used to meansure how good the model is. So I will now apply this to the model to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE Random Forest V6: 0.058563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "def get_root_mean_squared_log_error(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    return np.sqrt(mean_squared_log_error(y, y_pred))\n",
    "\n",
    "rmsle = get_root_mean_squared_log_error(rand_forest_v6, X_train_top_50_processed, y_train)\n",
    "print('RMSLE Random Forest V6: {:.6f}'.format(rmsle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results on Kaggle, the best is 0.00044. If the training result was repesentive of the test set, that would put us around 60th place. I will apply some cross validation to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rand_forest_v6, X_train_top_50_processed, y_train, cv=3, scoring='neg_mean_squared_log_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSLE Cross Val Random Forest V6: 0.150495\n"
     ]
    }
   ],
   "source": [
    "print('Mean RMSLE Cross Val Random Forest V6: {:.6f}'.format(np.sqrt(-scores).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results shows a more likely outcome of the model on a test dataset. This result puts us deep down on the average for this dataset.\n",
    "\n",
    "I will now try using a few others, to see if there is any more we can get from this dataset before applying PCA or manifold approaches to reudce the number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge, Ridge, PassiveAggressiveRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "\n",
    "# TODO - Try other models here\n",
    "clfs = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
